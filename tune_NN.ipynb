{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VasylVasylenko/trash_demo/blob/main/tune_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a15552",
      "metadata": {
        "id": "33a15552"
      },
      "outputs": [],
      "source": [
        "# A private key to get read access to the fredholm-solving repo\n",
        "PRIVATE_SSH_KEY: str = \\\n",
        "\"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAABlwAAAAdzc2gtcn\n",
        "NhAAAAAwEAAQAAAYEA1HIjZYoD4kKXbUBNP5e8qBRrXrQmbkF3MPhucssmBkrMPWXSJO1u\n",
        "QJC/NeuLIdAS7OcTZTzjXqJDlT99FZHkw3V4GvQ9FgO1EU2KlcgaLrMU6QXZrwN6T3heQi\n",
        "c40a07ASJzAXsSxE3PO1ZNkwymbdVfxSFUBPWhipon3BaiCM7ineMeGe+OH8BqdZu7AOID\n",
        "MkGq7F2cAtOTBYxNHn27ZJH810BGXWofuOSbAaz3mZhNs8kyF9vKqpAANxZITFqV+LRjVN\n",
        "6qFwmZB6cguJ6t3OKNSZPvzWlL/GvvD1OCUU9llSXjKvL7VDCDhe75Q1dt8Z2ckXNuMm8e\n",
        "p7z1czEVaA5leCYaf0JyeYvvBYXGbdLoaiiKfrFMOmzMosandwdhxXz2LbKdby7+ir5fq3\n",
        "WHsoeQBQdbiyFfIsKJ2m3NVrJcz3Ph8i3WcW44KLRBKIOtwoc3BgwQ0Qo8BhvvwYfTS2NE\n",
        "MypfhEIlOP0Y+kJzFjRmC7GrNiAxpK+uC6L02SYtAAAFkEVyJ7VFcie1AAAAB3NzaC1yc2\n",
        "EAAAGBANRyI2WKA+JCl21ATT+XvKgUa160Jm5BdzD4bnLLJgZKzD1l0iTtbkCQvzXriyHQ\n",
        "EuznE2U8416iQ5U/fRWR5MN1eBr0PRYDtRFNipXIGi6zFOkF2a8Dek94XkInONGtOwEicw\n",
        "F7EsRNzztWTZMMpm3VX8UhVAT1oYqaJ9wWogjO4p3jHhnvjh/AanWbuwDiAzJBquxdnALT\n",
        "kwWMTR59u2SR/NdARl1qH7jkmwGs95mYTbPJMhfbyqqQADcWSExalfi0Y1TeqhcJmQenIL\n",
        "ierdzijUmT781pS/xr7w9TglFPZZUl4yry+1Qwg4Xu+UNXbfGdnJFzbjJvHqe89XMxFWgO\n",
        "ZXgmGn9CcnmL7wWFxm3S6Gooin6xTDpszKLGp3cHYcV89i2ynW8u/oq+X6t1h7KHkAUHW4\n",
        "shXyLCidptzVayXM9z4fIt1nFuOCi0QSiDrcKHNwYMENEKPAYb78GH00tjRDMqX4RCJTj9\n",
        "GPpCcxY0ZguxqzYgMaSvrgui9NkmLQAAAAMBAAEAAAGBAJjgvfoe1Gao1wFmiXBeyAMIFq\n",
        "/i4djrwVL7I7f12poij1ELiarLNVC/GOo7Yzbk3gmey8VJiLEcAZhQRLoV79J8IP78jUzf\n",
        "RBh8fWMFyVmbw0tgy2J3FThE/UeLpAa3K0PIv4vsPfgHqj4f/9j2/HkDWFSqhCTBggsUne\n",
        "RyYQ4HmupVet7dFaBhvfp+I5ciDXzH5rELN+6MxDr02LY9cnGP4Kwhc8FbUhKiZ61QBCmC\n",
        "gUAEY8jpgLE2yQDbRxGzCPN3Er084+sGIMSUD11mgyIajevw2lZMiG5uHBeFOCb0t0a55b\n",
        "rWOi3/Q1MV+UWSZq+y9HRK6mDn+hqZelkXyc0lMStujOkqbfCJnsSFrAJ7UpG3EPINpsFN\n",
        "Rj5nojuOVwX7RyRphn+TQffdtJ/QORzKOlSluLI+SBCtDfJlyU2/+JnxR7Koc1/ALPS53C\n",
        "Yk3+VqnSBG+36Ujn30f29nfwmFMPstF65kLhJ1lWM5h5FfSg+LjmyS/wRd8iPjqV/1fQAA\n",
        "AMB201Phyr/EjI6UMiflXkFCW3Hjy7bpqOj1QtL3tq3CbOkJi7cXYJaewWcJHeDCCtqQ0H\n",
        "TeTD0zMFPFEEFi7GJGo/Tz33+IRdH3G4XfuOSDuv4VemBa1gmXuazyUqbP9kDKRB1QD6+e\n",
        "LVd1zh/8gd73ZUeSq+RNJT2ZuUajOwUHMHxvac8+25bwJETR2//likaOENRhm4GHBBVzTQ\n",
        "rp1/Eq5F9eN5CMBJlwgfByw3F9CGnGdQ0DNkSYUwSgu/ZY+esAAADBAOqUpdpBQlPAqs9W\n",
        "lmKHE5kLVUbx+xms4cm3iG0zDWuZLcLjyKVgrPTz8nUj5k5Xk6PwVlP5B0/69uGpMXSIk8\n",
        "V0BUx2Yw1ZoRxQnQfs9Kw2WDztbJmBzPFGI9j2DvsuN9MSMxhThwwp3473vzUdfAq8gDfF\n",
        "f8rydRFUJM/zfTzOLDhYQub7BuxU4Y9qy1Fwkpkxv2gi2nTMUjx+hIBfuC2d7Tu4Ju6PC2\n",
        "eKAon0cCFGdAEl68OpbO4kPSxoARbpvwAAAMEA59gWLJ5uL1PrGxRFbvhqI/qRMtYelz53\n",
        "J8keGRyONqs8SrFsRajydzix0UraLi00PjKRmqgnFRNIjTVE0chOMT2ArUUuO2tPv91gwS\n",
        "xRPLBokRnnQ9sUI3OwKsIKBO9KokdXn3Ca0uWV6Nl3KV9oFkWUz1uR6pVJ7NbIAtd8AGpO\n",
        "5uGutbxiEz6gU0fASFscc6jdBv7E3p3NX55E4gye17lUbJeRY0GHfH/4Oe5Gd83zAL07So\n",
        "a6xaQIjEySG3MTAAAAE2FjY2VuZG9AYWNjZW5kb2hvc3QBAgMEBQYH\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "205395c8",
      "metadata": {
        "id": "205395c8"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "import os.path as osp\n",
        "from typing import List, Optional\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import matplotlib\n",
        "import shutil\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torchsummary import summary\n",
        "from typing import Tuple\n",
        "from skimage.metrics import structural_similarity\n",
        "from functools import partial\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.colorbar as mcolorbar\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x_tS6vTLEQXF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_tS6vTLEQXF",
        "outputId": "457e6f57-2a8d-4ca6-baef-5c56744e7275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "source_folder = 'drive/MyDrive/dataset'\n",
        "target_folder = '/content/resources/simple_data'\n",
        "\n",
        "if not osp.exists(target_folder):\n",
        "    shutil.copytree(source_folder, target_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59484b75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59484b75",
        "outputId": "7cbc1b41-fbb6-4aaa-e427-55ad5d2e7c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-8405f9f3\n",
            "# github.com:22 SSH-2.0-babeld-8405f9f3\n",
            "# github.com:22 SSH-2.0-babeld-8405f9f3\n",
            "# github.com:22 SSH-2.0-babeld-8405f9f3\n",
            "# github.com:22 SSH-2.0-babeld-57ca1323\n",
            "Hi MrYoman/fredholm-solving! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into 'fredholm-solving'...\n",
            "remote: Enumerating objects: 1101, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 1101 (delta 113), reused 107 (delta 47), pack-reused 914\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 2.30 MiB | 13.29 MiB/s, done.\n",
            "Resolving deltas: 100% (706/706), done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Clone repo if we are running notebook in colab\n",
        "RUNNING_IN_COLAB: bool = osp.basename(os.getcwd()) == 'content'\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    # add the ssh key\n",
        "    ! mkdir -p /root/.ssh\n",
        "    with open(r'/root/.ssh/id_rsa', 'w', encoding='utf8') as fh:\n",
        "        fh.write(PRIVATE_SSH_KEY)\n",
        "    ! chmod 600 /root/.ssh/id_rsa\n",
        "    ! ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "    # test setup\n",
        "    ! ssh -T git@github.com\n",
        "    # clone repo\n",
        "    ! rm -rf fredholm-solving\n",
        "    ! git clone git@github.com:MrYoman/fredholm-solving.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7ef4fc",
      "metadata": {
        "id": "6c7ef4fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    FREDHOLM_SOLVING_PATH = osp.normpath(osp.join(os.getcwd(), 'fredholm-solving'))\n",
        "else:\n",
        "    FREDHOLM_SOLVING_PATH = osp.normpath(osp.join(os.getcwd(), '..'))\n",
        "sys.path.append(FREDHOLM_SOLVING_PATH)\n",
        "\n",
        "\n",
        "from fredholm_solving.core.nn import XiEffNet\n",
        "from fredholm_solving import (BatchSample, E_Ext_Class, GreenClass, PrecalculatedDataloader, PrecalculatedDataset,\n",
        "                              SampleMetadata, Xi, calc_E_on_grid, create_A_b)\n",
        "from audit.logic import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "samples = ['char_0_0000000', 'char_2_0000000', 'char_3_0000000', 'char_5_0000000', 'char_7_0000000', 'char_A_0000000', 'char_C_0000000', 'char_D_0000000', 'char_E_0000000', 'char_F_0000000', 'char_G_0000000', 'char_J_0000000', 'char_L_0000000', 'char_O_0000000', 'char_Q_0000000', 'char_R_0000000', 'char_T_0000000', 'char_U_0000000', 'char_X_0000000', 'char_Y_0000000', 'char_Z_0000000', 'convex_0000000', 'convex_0000001', 'convex_0000002', 'convex_0000003', 'convex_0000004', 'convex_0000005', 'convex_0000006', 'convex_0000007', 'convex_0000008', 'convex_0000009', 'convex_0000010', 'convex_0000011', 'convex_0000012', 'convex_0000013', 'union__ball_ball__0000000', 'union__ball_ellipse__0000000', 'union__ball_ellipse__0000001', 'union__ball_rectangle__0000000', 'union__ball_rectangle__0000001', 'union__ball_rectangle__0000002', 'union__ball_rectangle__0000003', 'union__convex_convex__0000000', 'union__convex_rectangle__0000000', 'union__convex_rectangle__0000001', 'union__convex_rectangle__0000002', 'union__convex_rectangle__0000003', 'union__ellipse_ball__0000000', 'union__ellipse_ball__0000001', 'union__rectangle_ball__0000000', 'union__rectangle_convex__0000000', 'union__rectangle_convex__0000001']\n",
        "\n",
        "folder = '/content/resources/simple_data/E_map'\n",
        "for f in os.listdir(folder):\n",
        "    if not any( s in f for s in samples):\n",
        "        os.remove(os.path.join(folder, f))\n",
        "\n",
        "folder = '/content/resources/simple_data/metadata'\n",
        "for f in os.listdir(folder):\n",
        "    if not any( s in f for s in samples):\n",
        "        os.remove(os.path.join(folder, f))"
      ],
      "metadata": {
        "id": "J45mNzkxGV-E"
      },
      "id": "J45mNzkxGV-E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JCqMOuJSG_KM",
      "metadata": {
        "id": "JCqMOuJSG_KM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "SINGLE_SAMPLE_SERIALIZED_DATA_PATH: str = osp.join('./', 'resources', 'simple_data')\n",
        "\n",
        "\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    DEVICE = 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DK7KTD8zHBvG",
      "metadata": {
        "id": "DK7KTD8zHBvG"
      },
      "outputs": [],
      "source": [
        "single_sample_serialized_dataset = PrecalculatedDataset(SINGLE_SAMPLE_SERIALIZED_DATA_PATH)\n",
        "single_sample_serialized_dataloader = PrecalculatedDataloader(single_sample_serialized_dataset)\n",
        "batch_data: BatchSample\n",
        "\n",
        "Nx, Ny, N, xy_grid, delta, G = single_sample_serialized_dataset.extract_space_data()\n",
        "mask_full = np.zeros(N) == 0\n",
        "gmat_full = torch.from_numpy(G(xy_grid[np.newaxis, mask_full, :], xy_grid[:, np.newaxis, :], dtype=np.float32)).to(DEVICE)\n",
        "mask_full_device = torch.from_numpy(mask_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iSEXa5_XHUVu",
      "metadata": {
        "id": "iSEXa5_XHUVu"
      },
      "outputs": [],
      "source": [
        "class OptStub:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "opt = OptStub(d_input = 2,\n",
        "    n_layers = 8,\n",
        "    d_filter = 512,\n",
        "    use_pos_enc = True,\n",
        "    pos_enc_freq = 7,\n",
        "    sine = True,\n",
        "    std=0.0,\n",
        "    lr=1.,\n",
        "    w_xi=0.01,\n",
        "    n_step=10)\n",
        "\n",
        "\n",
        "root_results = 'drive/MyDrive/results'\n",
        "experiment_name = os.path.join(root_results, \"tune_small\")  # replace this with your experiment's name\n",
        "\n",
        "if os.path.exists(experiment_name):\n",
        "    shutil.rmtree(experiment_name)\n",
        "\n",
        "os.makedirs(experiment_name, exist_ok=True)  # create a directory for the experiment if it doesn't exist\n",
        "\n",
        "def calc_iou(opt):\n",
        "    all_metrics = dict()\n",
        "    try:\n",
        "        for batch_data in single_sample_serialized_dataloader:\n",
        "            E_map, E_ext, loss_mask_cpu, loss_mask2d, obj_mask, sample_name = batch_data.extract_data()\n",
        "            metrics = []\n",
        "            sample_name = str(sample_name)[2:-2]\n",
        "\n",
        "            xy_grid_device = torch.tensor(xy_grid, dtype=torch.float32).to(DEVICE)\n",
        "            xieff_nn = XiEffNet(xy_grid=xy_grid_device, delta=delta, d_input=opt.d_input,\n",
        "                                n_layers=opt.n_layers, d_filter=opt.d_filter,\n",
        "                                use_pos_enc=opt.use_pos_enc, pos_enc_freq=opt.pos_enc_freq,\n",
        "                                sine=opt.sine, skip=(opt.n_layers//2+1,)).to(DEVICE)\n",
        "            E_map_noise = (E_map + torch.randn_like(E_map) * opt.std).to(DEVICE)\n",
        "            E0 = torch.tensor(E_ext, dtype=torch.float32).to(DEVICE)\n",
        "            E_exp = torch.tensor(E_map_noise.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
        "            E_target = torch.tensor(E_map.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
        "            loss_mask = torch.tensor(loss_mask_cpu, dtype=torch.bool).to(DEVICE)\n",
        "            gmat = gmat_full[..., loss_mask_cpu].contiguous().to(DEVICE)\n",
        "\n",
        "            optimizer = torch.optim.LBFGS(filter(lambda p: p.requires_grad, xieff_nn.parameters()), lr=opt.lr,\n",
        "                                          line_search_fn='strong_wolfe', max_iter=30)\n",
        "\n",
        "            def optimize_step(optimizer, xi_nn, gmat, mask, E0, E_exp, w_xi):\n",
        "                optimizer.zero_grad()\n",
        "                E, xieff_for_loss = xi_nn.inference_E(mask, gmat, E0)\n",
        "                loss_E = F.huber_loss(E, E_exp[:, mask], delta=1.0)\n",
        "                loss_X = F.l1_loss(xieff_for_loss, torch.zeros_like(xieff_for_loss))\n",
        "                loss = loss_E + loss_X * w_xi\n",
        "                if not torch.isnan(loss):\n",
        "                    loss.backward()\n",
        "                return loss\n",
        "\n",
        "            closure = partial(optimize_step, optimizer=optimizer, xi_nn=xieff_nn, gmat=gmat, mask=loss_mask, E0=E0,\n",
        "                              E_exp=E_exp, w_xi=opt.w_xi)\n",
        "\n",
        "            best_loss = float('inf')\n",
        "            for i in range(opt.n_step):\n",
        "                loss = optimizer.step(closure)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    E_pred, _ = xieff_nn.inference_E(mask_full, gmat_full, E0)\n",
        "                    opa = xieff_nn.get_grid_state().permute(1, 0).cpu().detach().numpy()\n",
        "                    magnitudes = np.linalg.norm(opa, axis=0).reshape(Ny, Nx)\n",
        "                    metrics_list = calculate_metrics(E_target, E_pred, E_map, E_pred.reshape(-1, Nx, Ny), loss_mask2d,\n",
        "                                                     loss_mask, obj_mask.reshape(Nx, Ny), magnitudes)\n",
        "                    metrics.append(metrics_list)\n",
        "\n",
        "            all_metrics[sample_name] = metrics\n",
        "    except Exception as e:\n",
        "        # Log the error\n",
        "        all_metrics['error'] = str(e)\n",
        "        with open('error_metrics.json', 'w') as f:\n",
        "            json.dump(all_metrics, f, indent=4)\n",
        "    finally:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate the average metrics across all samples\n",
        "    avg_metrics = dict()\n",
        "    for step in range(opt.n_step):\n",
        "        metrics_sum = np.zeros(5)\n",
        "        for metrics in all_metrics.values():\n",
        "            if isinstance(metrics, list):  # Ensure we skip the error log if present\n",
        "                metrics_sum += np.array(metrics[step])\n",
        "        avg_metrics[step] = metrics_sum / len([m for m in all_metrics.values() if isinstance(m, list)])\n",
        "\n",
        "    best_iou = max(v[-1] for step, v in avg_metrics.items() if isinstance(v, np.ndarray))\n",
        "\n",
        "    return best_iou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbdh0sYcGHel",
        "outputId": "080fb4dd-e591-4541-f20c-7d22094a2ef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'d_input': 2, 'n_layers': 7, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 6, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/fredholm-solving/fredholm_solving/core/nn.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.xy_grid_torch = torch.tensor(xy_grid, dtype=torch.float32)\n",
            "\n",
            "<ipython-input-9-24f7b4704318>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  E_exp = torch.tensor(E_map_noise.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
            "\n",
            "<ipython-input-9-24f7b4704318>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  E_target = torch.tensor(E_map.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
            "\n",
            "/content/fredholm-solving/audit/logic.py:60: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim = structural_similarity(E_target_2d.transpose(2, 1,0), E_pred_2d.transpose(2,1,0), multichannel=True)\n",
            "\n",
            "/content/fredholm-solving/audit/logic.py:63: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim_mask = structural_similarity(E_target_2d.transpose(2, 1,0), E_pred_2d.transpose(2,1,0), multichannel=True)\n",
            "\n",
            "/content/fredholm-solving/fredholm_solving/core/nn.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.xy_grid_torch = torch.tensor(xy_grid, dtype=torch.float32)\n",
            "\n",
            "<ipython-input-9-24f7b4704318>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  E_exp = torch.tensor(E_map_noise.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
            "\n",
            "<ipython-input-9-24f7b4704318>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  E_target = torch.tensor(E_map.reshape(2, -1), dtype=torch.float32).to(DEVICE)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'d_input': 2, 'n_layers': 9, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 9, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 5, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 6, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 4, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 5, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 3, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 3, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 4, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 6, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 4, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 8, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 4, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 5, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            "{'d_input': 2, 'n_layers': 11, 'd_filter': 256, 'use_pos_enc': True, 'pos_enc_freq': 4, 'sine': True, 'std': 0.0, 'lr': 1.0, 'w_xi': 0.0, 'n_step': 10}\n",
            " 16%|█▌        | 8/50 [48:46<3:48:34, 326.54s/trial, best loss: -0.6328644114406253]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-24f7b4704318>:89: RuntimeWarning: invalid value encountered in divide\n",
            "  avg_metrics[step] = metrics_sum / len([m for m in all_metrics.values() if isinstance(m, list)])\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 8/50 [49:00<3:48:34, 326.54s/trial, best loss: -0.6328644114406253]"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the search space for the parameters\n",
        "space = {\n",
        "    'n_layers': hp.quniform('n_layers', 5, 12, 1),  # since values are [4, 6, 8, 10, 12, 14], q=2 will step through these values\n",
        "    'd_filter': hp.choice('d_filter', [256,]),  # since the values are multiples of 64\n",
        "    'pos_enc_freq': hp.quniform('pos_enc_freq', 3, 10, 1),  # we will conditionally use this value within the function\n",
        "    #'lr': hp.loguniform(low=-3*np.log(10), high=2*np.log(10)),\n",
        "    #'w_xi': hp.loguniform(low=-10*np.log(10), high=1*np.log(10)),\n",
        "}\n",
        "\n",
        "default_params = {\n",
        "    'd_input': 2,\n",
        "    'n_layers': 9,  # Will be overwritten by Hyperopt\n",
        "    'd_filter': 512,  # Will be overwritten by Hyperopt\n",
        "    'use_pos_enc': True,  # Will be overwritten by Hyperopt\n",
        "    'pos_enc_freq': 7,  # Will be overwritten by Hyperopt if use_pos_enc is True\n",
        "    'sine': True,  # Will be overwritten by Hyperopt if use_pos_enc is True\n",
        "    'std': 0.0,\n",
        "    'lr': 1.0,\n",
        "    'w_xi': 0.00,\n",
        "    'n_step': 10,\n",
        "}\n",
        "# Initialize a counter for the number of calls to the objective function\n",
        "call_count = 0\n",
        "\n",
        "# Define the objective function that Hyperopt will minimize\n",
        "def hyperopt_objective(params):\n",
        "    global call_count\n",
        "    call_count += 1\n",
        "\n",
        "    tuned_params = default_params.copy()\n",
        "    tuned_params.update({\n",
        "        'n_layers': int(params['n_layers']),\n",
        "        'd_filter': int(params['d_filter']),\n",
        "        'pos_enc_freq': int(params['pos_enc_freq'])\n",
        "        #'lr': params['lr'],\n",
        "        #'w_xi': params['w_xi']\n",
        "    })\n",
        "\n",
        "    # Create an OptStub object with the updated parameters\n",
        "    opt = OptStub(**tuned_params)\n",
        "    print(tuned_params)\n",
        "    iou = calc_iou(opt)\n",
        "\n",
        "    # Save the parameters and IoU to a file\n",
        "    opt_dict = opt.__dict__\n",
        "    opt_dict['iou'] = iou\n",
        "    opt_json = json.dumps(opt_dict, indent=4)\n",
        "    file_path = os.path.join(experiment_name, f'opt_call_{call_count}_{iou}.json')\n",
        "    with open(file_path, 'w') as json_file:\n",
        "        json_file.write(opt_json)\n",
        "\n",
        "    # Negate the IoU for maximization\n",
        "    return {'loss': -iou, 'status': STATUS_OK}\n",
        "\n",
        "# Run the optimization process\n",
        "trials = Trials()\n",
        "best_params = fmin(\n",
        "    fn=hyperopt_objective,\n",
        "    space=space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50,  # Run 50 trials\n",
        "    trials=trials\n",
        ")\n",
        "\n",
        "print(best_params)\n"
      ],
      "id": "Pbdh0sYcGHel"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dqRTmpg3M6lB",
      "metadata": {
        "id": "dqRTmpg3M6lB"
      },
      "outputs": [],
      "source": [
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "solve_NN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "bed8eb5038728f99873e4d60e9be50cd1a40aaf5c90f61e800d44267733d40d1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}